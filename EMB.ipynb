{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# get kaggle json to download the dataset \n",
        "! pip install kaggle\n",
        "! rm -rf ~/.kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! wget https://transfer.sh/Bh4pIY/kaggle.json\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "CHSpvGBPlHQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec55e9b4-a9b2-4236-b5b1-5f25096d43e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.24.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.46.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "--2022-04-01 23:37:05--  https://transfer.sh/Bh4pIY/kaggle.json\n",
            "Resolving transfer.sh (transfer.sh)... 144.76.136.153, 2a01:4f8:200:1097::2\n",
            "Connecting to transfer.sh (transfer.sh)|144.76.136.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71 [application/json]\n",
            "Saving to: ‘kaggle.json.2’\n",
            "\n",
            "kaggle.json.2       100%[===================>]      71  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-01 23:37:06 (505 KB/s) - ‘kaggle.json.2’ saved [71/71]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchvison inbuilt dataset is not working, hence have to use kaggle   \n",
        "! kaggle datasets download jessicali9530/celeba-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPhtytXCl7Cb",
        "outputId": "19589984-5094-4bf2-9a4a-06da969532c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading celeba-dataset.zip to /content\n",
            " 99% 1.31G/1.33G [00:12<00:00, 97.0MB/s]\n",
            "100% 1.33G/1.33G [00:13<00:00, 110MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the dataset\n",
        "!unzip celeba-dataset.zip"
      ],
      "metadata": {
        "id": "jD2CyTStm8qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone and install all the required repos and packages\n",
        "! git clone https://github.com/skp-github/MaskTheFace.git\n",
        "! git clone https://github.com/skp-github/3DDFA.git\n",
        "! git clone https://github.com/skp-github/3DDFA_V2.git\n",
        "! pip install mtcnn\n",
        "! pip install mediapipe\n",
        "! pip install dotmap\n",
        "! pip install face-alignment"
      ],
      "metadata": {
        "id": "FPsg8E9xoP7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation will take time **(10-20 mins approx)**\n"
      ],
      "metadata": {
        "id": "Ozwe6pXbRN9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup and install all repos \n",
        "\n",
        "# 1. setup mask the face repo \n",
        "%cd MaskTheFace\n",
        "! pip install -r requirements.txt\n",
        "%cd ..\n",
        "\n",
        "# 2. Setup 3DDFA repo\n",
        "%cd 3DDFA/\n",
        "! pip install -r requirements.txt\n",
        "%cd utils/cython/\n",
        "! python setup.py build_ext -i\n",
        "%cd ../../..\n",
        "\n",
        "# 3. Setup 3DDFA_V2\n",
        "%cd 3DDFA_V2\n",
        "!sh ./build.sh\n",
        "%cd .."
      ],
      "metadata": {
        "id": "LTipwxVrwxrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create subset dataset from 200k images\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NTNPEReYTz2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "EjBFGPMyQyPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf '/content/sample_dataset/'\n",
        "!mkdir '/content/sample_dataset/'"
      ],
      "metadata": {
        "id": "hNt7ULYW11x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "# select random sample of images \n",
        "# you can change sample size(number of images for the experiment) to increase the dataset \n",
        "def create_subset_dataset(img_dataset_path,sample_size=150):\n",
        "  # files number list i.e 000001.py\n",
        "  files_list = []\n",
        "  # image absolute path i.e \n",
        "  dir_path = []\n",
        "  while sample_size !=0: \n",
        "    # generate a random image number\n",
        "    image_number = str(random.randint(1, 10000))\n",
        "    # pad the random number i.e 23 => 0000 (total 6 digits required)\n",
        "    trailing_zeros = \"0\"*(6 - len(image_number) )\n",
        "    # image_number = \"0000\"+\"23\"+\"+\".jpg\" => 000023.jpg\n",
        "    image_number = trailing_zeros + image_number + \".jpg\"\n",
        "    # check if this image is already used \n",
        "    if image_number in files_list:\n",
        "      continue\n",
        "    #create image path i.e \"/content/img_align_celeba/img_align_celeba/\"+\"000023.jpg\" => \"/content/img_align_celeba/img_align_celeba/000023.jpg\"\n",
        "    image_path = img_dataset_path + image_number \n",
        "    # append the image_number i.e \"000023.jpg\"\n",
        "    files_list.append(image_number)\n",
        "    # append the image_path i.e \"/content/img_align_celeba/img_align_celeba/000023.jpg\"\n",
        "    dir_path.append(image_path)\n",
        "    # reduce the sample size\n",
        "    sample_size -= 1\n",
        "  # copy images from dataset folder to sample_dataset folder\n",
        "  base_dst_dir = '/content/sample_dataset/'\n",
        "  for i  in range(0, len(files_list)):\n",
        "    dst_dir = base_dst_dir + files_list[i]\n",
        "    shutil.copy(dir_path[i], dst_dir)\n",
        "\n",
        "create_subset_dataset('/content/img_align_celeba/img_align_celeba/')\n",
        "# remove 1GB dataset \n",
        "!rm -rf img_align_celeba/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWcdqgorshgn",
        "outputId": "722762e6-355e-4e50-db8a-a1edd1d62d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/img_align_celeba/img_align_celeba/005377.jpg', '/content/img_align_celeba/img_align_celeba/001673.jpg', '/content/img_align_celeba/img_align_celeba/009264.jpg', '/content/img_align_celeba/img_align_celeba/004107.jpg', '/content/img_align_celeba/img_align_celeba/007770.jpg', '/content/img_align_celeba/img_align_celeba/002576.jpg', '/content/img_align_celeba/img_align_celeba/000475.jpg', '/content/img_align_celeba/img_align_celeba/000389.jpg', '/content/img_align_celeba/img_align_celeba/007445.jpg', '/content/img_align_celeba/img_align_celeba/002136.jpg', '/content/img_align_celeba/img_align_celeba/002947.jpg', '/content/img_align_celeba/img_align_celeba/009364.jpg', '/content/img_align_celeba/img_align_celeba/009431.jpg', '/content/img_align_celeba/img_align_celeba/004634.jpg', '/content/img_align_celeba/img_align_celeba/006099.jpg', '/content/img_align_celeba/img_align_celeba/000549.jpg', '/content/img_align_celeba/img_align_celeba/000400.jpg', '/content/img_align_celeba/img_align_celeba/008474.jpg', '/content/img_align_celeba/img_align_celeba/004907.jpg', '/content/img_align_celeba/img_align_celeba/009925.jpg', '/content/img_align_celeba/img_align_celeba/002532.jpg', '/content/img_align_celeba/img_align_celeba/008233.jpg', '/content/img_align_celeba/img_align_celeba/002335.jpg', '/content/img_align_celeba/img_align_celeba/001974.jpg', '/content/img_align_celeba/img_align_celeba/004122.jpg', '/content/img_align_celeba/img_align_celeba/004949.jpg', '/content/img_align_celeba/img_align_celeba/006192.jpg', '/content/img_align_celeba/img_align_celeba/002453.jpg', '/content/img_align_celeba/img_align_celeba/000414.jpg', '/content/img_align_celeba/img_align_celeba/006130.jpg', '/content/img_align_celeba/img_align_celeba/007658.jpg', '/content/img_align_celeba/img_align_celeba/007794.jpg', '/content/img_align_celeba/img_align_celeba/002847.jpg', '/content/img_align_celeba/img_align_celeba/006450.jpg', '/content/img_align_celeba/img_align_celeba/001867.jpg', '/content/img_align_celeba/img_align_celeba/000583.jpg', '/content/img_align_celeba/img_align_celeba/004422.jpg', '/content/img_align_celeba/img_align_celeba/001063.jpg', '/content/img_align_celeba/img_align_celeba/003899.jpg', '/content/img_align_celeba/img_align_celeba/008507.jpg', '/content/img_align_celeba/img_align_celeba/009730.jpg', '/content/img_align_celeba/img_align_celeba/005047.jpg', '/content/img_align_celeba/img_align_celeba/005528.jpg', '/content/img_align_celeba/img_align_celeba/001256.jpg', '/content/img_align_celeba/img_align_celeba/008849.jpg', '/content/img_align_celeba/img_align_celeba/009705.jpg', '/content/img_align_celeba/img_align_celeba/004403.jpg', '/content/img_align_celeba/img_align_celeba/004512.jpg', '/content/img_align_celeba/img_align_celeba/002764.jpg', '/content/img_align_celeba/img_align_celeba/001899.jpg', '/content/img_align_celeba/img_align_celeba/006530.jpg', '/content/img_align_celeba/img_align_celeba/006780.jpg', '/content/img_align_celeba/img_align_celeba/008443.jpg', '/content/img_align_celeba/img_align_celeba/008872.jpg', '/content/img_align_celeba/img_align_celeba/002199.jpg', '/content/img_align_celeba/img_align_celeba/008159.jpg', '/content/img_align_celeba/img_align_celeba/003195.jpg', '/content/img_align_celeba/img_align_celeba/007802.jpg', '/content/img_align_celeba/img_align_celeba/007161.jpg', '/content/img_align_celeba/img_align_celeba/005358.jpg', '/content/img_align_celeba/img_align_celeba/001557.jpg', '/content/img_align_celeba/img_align_celeba/007105.jpg', '/content/img_align_celeba/img_align_celeba/008973.jpg', '/content/img_align_celeba/img_align_celeba/009601.jpg', '/content/img_align_celeba/img_align_celeba/009687.jpg', '/content/img_align_celeba/img_align_celeba/009295.jpg', '/content/img_align_celeba/img_align_celeba/006171.jpg', '/content/img_align_celeba/img_align_celeba/005927.jpg', '/content/img_align_celeba/img_align_celeba/002855.jpg', '/content/img_align_celeba/img_align_celeba/008345.jpg', '/content/img_align_celeba/img_align_celeba/002195.jpg', '/content/img_align_celeba/img_align_celeba/002759.jpg', '/content/img_align_celeba/img_align_celeba/009774.jpg', '/content/img_align_celeba/img_align_celeba/000442.jpg', '/content/img_align_celeba/img_align_celeba/006202.jpg', '/content/img_align_celeba/img_align_celeba/004247.jpg', '/content/img_align_celeba/img_align_celeba/003404.jpg', '/content/img_align_celeba/img_align_celeba/008962.jpg', '/content/img_align_celeba/img_align_celeba/009599.jpg', '/content/img_align_celeba/img_align_celeba/004722.jpg', '/content/img_align_celeba/img_align_celeba/004798.jpg', '/content/img_align_celeba/img_align_celeba/006036.jpg', '/content/img_align_celeba/img_align_celeba/008484.jpg', '/content/img_align_celeba/img_align_celeba/002047.jpg', '/content/img_align_celeba/img_align_celeba/005329.jpg', '/content/img_align_celeba/img_align_celeba/004334.jpg', '/content/img_align_celeba/img_align_celeba/004183.jpg', '/content/img_align_celeba/img_align_celeba/000954.jpg', '/content/img_align_celeba/img_align_celeba/002888.jpg', '/content/img_align_celeba/img_align_celeba/005241.jpg', '/content/img_align_celeba/img_align_celeba/004559.jpg', '/content/img_align_celeba/img_align_celeba/005312.jpg', '/content/img_align_celeba/img_align_celeba/003370.jpg', '/content/img_align_celeba/img_align_celeba/002088.jpg', '/content/img_align_celeba/img_align_celeba/001212.jpg', '/content/img_align_celeba/img_align_celeba/001141.jpg', '/content/img_align_celeba/img_align_celeba/009738.jpg', '/content/img_align_celeba/img_align_celeba/003509.jpg', '/content/img_align_celeba/img_align_celeba/004850.jpg', '/content/img_align_celeba/img_align_celeba/002200.jpg', '/content/img_align_celeba/img_align_celeba/002915.jpg', '/content/img_align_celeba/img_align_celeba/008059.jpg', '/content/img_align_celeba/img_align_celeba/008053.jpg', '/content/img_align_celeba/img_align_celeba/001676.jpg', '/content/img_align_celeba/img_align_celeba/009578.jpg', '/content/img_align_celeba/img_align_celeba/000176.jpg', '/content/img_align_celeba/img_align_celeba/007560.jpg', '/content/img_align_celeba/img_align_celeba/008993.jpg', '/content/img_align_celeba/img_align_celeba/009314.jpg', '/content/img_align_celeba/img_align_celeba/001611.jpg', '/content/img_align_celeba/img_align_celeba/000352.jpg', '/content/img_align_celeba/img_align_celeba/007814.jpg', '/content/img_align_celeba/img_align_celeba/001655.jpg', '/content/img_align_celeba/img_align_celeba/006047.jpg', '/content/img_align_celeba/img_align_celeba/000343.jpg', '/content/img_align_celeba/img_align_celeba/001819.jpg', '/content/img_align_celeba/img_align_celeba/008801.jpg', '/content/img_align_celeba/img_align_celeba/006605.jpg', '/content/img_align_celeba/img_align_celeba/003785.jpg', '/content/img_align_celeba/img_align_celeba/004029.jpg', '/content/img_align_celeba/img_align_celeba/009638.jpg', '/content/img_align_celeba/img_align_celeba/005222.jpg', '/content/img_align_celeba/img_align_celeba/007638.jpg', '/content/img_align_celeba/img_align_celeba/005187.jpg', '/content/img_align_celeba/img_align_celeba/002934.jpg', '/content/img_align_celeba/img_align_celeba/001868.jpg', '/content/img_align_celeba/img_align_celeba/008373.jpg', '/content/img_align_celeba/img_align_celeba/000241.jpg', '/content/img_align_celeba/img_align_celeba/005094.jpg', '/content/img_align_celeba/img_align_celeba/005031.jpg', '/content/img_align_celeba/img_align_celeba/003895.jpg', '/content/img_align_celeba/img_align_celeba/003663.jpg', '/content/img_align_celeba/img_align_celeba/004568.jpg', '/content/img_align_celeba/img_align_celeba/004895.jpg', '/content/img_align_celeba/img_align_celeba/002154.jpg', '/content/img_align_celeba/img_align_celeba/009251.jpg', '/content/img_align_celeba/img_align_celeba/009177.jpg', '/content/img_align_celeba/img_align_celeba/000348.jpg', '/content/img_align_celeba/img_align_celeba/008675.jpg', '/content/img_align_celeba/img_align_celeba/007099.jpg', '/content/img_align_celeba/img_align_celeba/007140.jpg', '/content/img_align_celeba/img_align_celeba/002175.jpg', '/content/img_align_celeba/img_align_celeba/002155.jpg', '/content/img_align_celeba/img_align_celeba/004631.jpg', '/content/img_align_celeba/img_align_celeba/003384.jpg', '/content/img_align_celeba/img_align_celeba/006812.jpg', '/content/img_align_celeba/img_align_celeba/001346.jpg', '/content/img_align_celeba/img_align_celeba/000434.jpg', '/content/img_align_celeba/img_align_celeba/008100.jpg', '/content/img_align_celeba/img_align_celeba/001666.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert images from the subset to masked images\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OXB_UQwcehMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mask the sample images\n",
        "%cd MaskTheFace/\n",
        "! python mask_the_face.py --path '/content/sample_dataset/'\n",
        "%cd .."
      ],
      "metadata": {
        "id": "HbJLn11kEgGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3DDFA on masked dataset\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8prFKra6evk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# landmarks from 3DDFA (68 points) => shape = (68,3)\n",
        "\n",
        "# remove all files from 3ddfa processed folder if any \n",
        "!rm -rf '/content/3ddfa_images/'\n",
        "# create 3ddfa processed folder if not already there  \n",
        "!mkdir '/content/3ddfa_images/'\n",
        "# remove files from 3ddfa processed folder sub folder landmarks  if any\n",
        "!rm -rf '/content/3ddfa_images/landmarks/'\n",
        "# create 3ddfa processed folder sub folder to store landmarks  if not already there\n",
        "!mkdir '/content/3ddfa_images/landmarks/'\n",
        "# cd in the repo\n",
        "%cd 3DDFA/\n",
        "# run main.py over the masked images , 3DDFA (images and landmarks are stored in the folders mentioned above )\n",
        "!python main.py -f '/content/masked_images/'\n",
        "%cd .."
      ],
      "metadata": {
        "id": "Lwn-afaZyLKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3DDFA_V2 on masked dataset\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nFODvzM7e4Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3DDFA2 landmarks points \n",
        "\n",
        "# exactly like 3DDFA similar process with 3DDFA_V2\n",
        "!rm -rf '/content/3ddfa2_images/'\n",
        "!mkdir '/content/3ddfa2_images/'\n",
        "!rm -rf '/content/3ddfa2_images/landmarks/'\n",
        "!mkdir '/content/3ddfa2_images/landmarks/'\n",
        "%cd 3DDFA_V2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFiJlWfwjNm4",
        "outputId": "786e0edf-af1b-459a-eb69-e68aac21ac5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/3DDFA_V2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages and files  \n",
        "import cv2\n",
        "import yaml\n",
        "\n",
        "from FaceBoxes import FaceBoxes\n",
        "from TDDFA import TDDFA\n",
        "from utils.render import render\n",
        "from utils.depth import depth\n",
        "from utils.pncc import pncc\n",
        "from utils.uv import uv_tex\n",
        "from utils.pose import viz_pose\n",
        "from utils.serialization import ser_to_ply, ser_to_obj\n",
        "from utils.functions import draw_landmarks, get_suffix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "emz79hIiluV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load config\n",
        "cfg = yaml.load(open('configs/mb1_120x120.yml'), Loader=yaml.SafeLoader)\n",
        "face_boxes = FaceBoxes()\n",
        "tddfa = TDDFA(gpu_mode=False, **cfg)\n",
        "img_path = '/content/masked_images/'\n",
        "dense_flag = False\n",
        "path, dirs, files = os.walk(img_path).__next__()\n",
        "destination_folder = \"/content/3ddfa2_images/\"\n",
        "for f in tqdm(files):\n",
        "  img_fp = path+f\n",
        "  img_ori = cv2.imread(img_fp)\n",
        "  boxes = face_boxes(img_ori)\n",
        "  param_lst, roi_box_lst = tddfa(img_ori, boxes)\n",
        "  ver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\n",
        "  wfp = destination_folder +\"landmarks/\" +'{}.txt'.format(img_fp.split(\"/\")[3][:-4])\n",
        "  # if landmarks generated\n",
        "  if ver_lst:\n",
        "    # save landmarks \n",
        "    np.savetxt(wfp, ver_lst[0], fmt='%.3f')\n",
        "    viz_wfp = destination_folder +'{}'.format(img_fp.split(\"/\")[3]) \n",
        "    # save images with landmarks  \n",
        "    draw_landmarks(img_ori, ver_lst, wfp=viz_wfp,dense_flag=dense_flag)\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "D8Tu7FdOmJFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face-Alignment(Arianb) on masked dataset\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2W2BEhIRfHt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# face-alignment landmarks points \n",
        "!rm -rf '/content/face_alignment_images/'\n",
        "!mkdir '/content/face_alignment_images/'\n",
        "!rm -rf '/content/face_alignment_images/landmarks/'\n",
        "!mkdir '/content/face_alignment_images/landmarks/'"
      ],
      "metadata": {
        "id": "jsL2mAAC3JnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required packages \n",
        "import face_alignment\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def draw_landmarks(img, pts, style='fancy', wfp=None, show_flag=True, **kwargs):\n",
        "    \"\"\"Draw landmarks using matplotlib\"\"\"\n",
        "    height, width = img.shape[:2]\n",
        "    plt.figure(figsize=(12, height / width * 12))\n",
        "    plt.imshow(img[..., ::-1])\n",
        "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
        "    plt.axis('off')\n",
        "\n",
        "    dense_flag = kwargs.get('dense_flag')\n",
        "\n",
        "    if not type(pts) in [tuple, list]:\n",
        "        pts = [pts]\n",
        "    for i in range(len(pts)):\n",
        "        if dense_flag:\n",
        "            plt.plot(pts[i][0, ::6], pts[i][1, ::6], 'o', markersize=0.4, color='c', alpha=0.7)\n",
        "        else:\n",
        "            alpha = 0.8\n",
        "            markersize = 4\n",
        "            lw = 1.5\n",
        "            color = kwargs.get('color', 'w')\n",
        "            markeredgecolor = kwargs.get('markeredgecolor', 'black')\n",
        "\n",
        "            nums = [0, 17, 22, 27, 31, 36, 42, 48, 60, 68]\n",
        "\n",
        "            # close eyes and mouths\n",
        "            plot_close = lambda i1, i2: plt.plot([pts[i][0, i1], pts[i][0, i2]], [pts[i][1, i1], pts[i][1, i2]],\n",
        "                                                 color=color, lw=lw, alpha=alpha - 0.1)\n",
        "            plot_close(41, 36)\n",
        "            plot_close(47, 42)\n",
        "            plot_close(59, 48)\n",
        "            plot_close(67, 60)\n",
        "\n",
        "            for ind in range(len(nums) - 1):\n",
        "                l, r = nums[ind], nums[ind + 1]\n",
        "                plt.plot(pts[i][0, l:r], pts[i][1, l:r], color=color, lw=lw, alpha=alpha - 0.1)\n",
        "\n",
        "                plt.plot(pts[i][0, l:r], pts[i][1, l:r], marker='o', linestyle='None', markersize=markersize,\n",
        "                         color=color,\n",
        "                         markeredgecolor=markeredgecolor, alpha=alpha)\n",
        "            \n",
        "    if wfp is not None:\n",
        "        plt.savefig(wfp, dpi=150)\n",
        "        print(f'Save visualization result to {wfp}')\n",
        "\n",
        "    if show_flag:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, flip_input=False, device=\"cpu\")\n",
        "img_path = '/content/masked_images/'\n",
        "path, dirs, files = os.walk(img_path).__next__()\n",
        "destination_folder = '/content/face_alignment_images/'\n",
        "for f in tqdm(files):\n",
        "  img_fp = path+f\n",
        "  img_ori = cv2.imread(img_fp)\n",
        "  preds = fa.get_landmarks(img_ori)\n",
        "  wfp = destination_folder +\"landmarks/\" +'{}.txt'.format(img_fp.split(\"/\")[3][:-4])\n",
        "  # if landmarks generated\n",
        "  if preds:\n",
        "    #save landmarks \n",
        "    np.savetxt(wfp, np.swapaxes(preds[0],0,1), fmt='%.3f')\n",
        "    viz_wfp = destination_folder +'{}'.format(img_fp.split(\"/\")[3]) \n",
        "    # save image with \n",
        "    draw_landmarks(img_ori, wfp=viz_wfp, pts=np.swapaxes(preds[0],0,1))"
      ],
      "metadata": {
        "id": "5bzMHB9u2Vk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Side Note**\n",
        "#### ***sample_dataset*** = certain number of random images picked for experiment(could have been avioded)\n",
        "#### ***masked_images*** = folder with masked images (uses sampled dataset directory)\n",
        "#### ***3ddfa_images*** (all 3ddfa processed images) = have a subfolder with landmarks  i.e 000001.py (image names) i.e 000001.txt (landmarks , (68,3))\n",
        "#### ***3ddfa2_images*** (all 3ddfa_v2 processed images) = have a subfolder with landmarks  i.e 000001.py (image names) i.e 000001.txt (landmarks, (68,3))\n",
        "#### ***face_alignment_images*** (all face_alignment_images images) = have a subfolder with landmarks i.e 000001.py (image names) i.e 000001.txt (landmarks, (68,3)) \n",
        "\n",
        "# **Ground truth landmarks are in list_landmarks_align_celeba.csv**\n",
        "#### for more details check this https://www.kaggle.com/datasets/jessicali9530/celeba-dataset?select=list_landmarks_align_celeba.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "ZyTuCWpcfYo1"
      }
    }
  ]
}